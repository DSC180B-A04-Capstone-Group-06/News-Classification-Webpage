## Text Classification

  Text Classification (TC) and Named-Entity Recognition (NER) are two fundamental tasks for many Natural Language Processing (NLP) applications, which involve understanding, extracting information, and categorizing the text. In order to achieve such goals, we utilized AutoPhrase (Jingbo Shang, 2018) and a pre-trained language NER model to extract quality phrases. Using these as part of our features, we are able to achieve high performance for a five class and a twenty class text classification dataset. Our project follows a similar setting as previous works with train, validation, and test datasets and comparing the results across different methods.
  
  Text classification is an important NLP task, which can be understood as a given set of text and labels. We want to create a classifier that can classify them in addition to other texts. Text classification tasks mainly involve understanding the text and extracting high quality phrases for model training. For example, if a text has "government" or "minister" as a frequent phrase or word, it is more likely to belong to 'Politics'. So, it is important for us to extract quality phrases and make sure they represent these documents well.

## Data Sets

  For our project, we have decided to use two news data sets: a BBC News data set and a 20 News data set.
  
  **BBC News dataset:** 
  
  - includes 2,225 documents
  - spans 2004-2005 
  - composed of five categories
    - entertainment
    - technology
    - politics
    - business
    - sports
  
  **20 News Groups dataset:** includes 18,000 news groups posts; composed of 20 categories (Computer, Science, Politics, Religion, etc.)

## Model

### AutoPhrase based Model

### Pre-trained NER based Model

## Experiment

## Result

### Result Matrix

## Conclusion

## Reference
